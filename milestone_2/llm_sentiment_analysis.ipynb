{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a6224a-1a88-4c3d-bb17-6cf636e2e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "CSV_FILE_PATH = 'ai_news_processed.csv'\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"API key not found.\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "model = genai.GenerativeModel('models/gemini-2.5-flash-lite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929f2536-997c-48a1-9f42-3776548c941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of (label, score) tuples\n",
    "def get_sentiment_data_in_batch(headlines: list) -> list:\n",
    "    numbered_headlines = \"\\n\".join([f\"{i+1}. {headline}\" for i, headline in enumerate(headlines)])\n",
    "\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze the sentiment of each news headline below. For each headline, provide:\n",
    "    1. A 'label' ('Positive', 'Negative', or 'Neutral').\n",
    "    2. A 'score', which is a float value between -1.00 (most negative) and 1.00 (most positive), where 0.00 is neutral, all values rounded to exactly two decimal places.\n",
    "\n",
    "    Provide the output as a single, valid JSON array of objects. Each object must have a \"label\" key and a \"score\" key.\n",
    "\n",
    "    Headlines:\n",
    "    {numbered_headlines}\n",
    "\n",
    "    JSON Array of Objects:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        cleaned_text = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "        \n",
    "        # list of dictionaries, e.g., [{\"label\": \"Positive\", \"score\": 0.8}, ...]\n",
    "        parsed_json = json.loads(cleaned_text)\n",
    "        \n",
    "        # json to tuple\n",
    "        results = []\n",
    "        for item in parsed_json:\n",
    "            label = item.get(\"label\", \"Error\")\n",
    "            score = item.get(\"score\", 0.0)\n",
    "            results.append((label, score)) #save as tuple\n",
    "\n",
    "        if len(results) == len(headlines):\n",
    "            return results\n",
    "        else:\n",
    "            print(\"Warning: Model returned a different number of sentiments than expected.\")\n",
    "            return [(\"Error\", 0.0)] * len(headlines)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during API call or JSON parsing: {e}\")\n",
    "        return [(\"Error\", 0.0)] * len(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c86150b-b177-4906-858d-eefa350abdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/30...\n",
      "Processing batch 2/30...\n",
      "Processing batch 3/30...\n",
      "Processing batch 4/30...\n",
      "Processing batch 5/30...\n",
      "Processing batch 6/30...\n",
      "Processing batch 7/30...\n",
      "Processing batch 8/30...\n",
      "Processing batch 9/30...\n",
      "Processing batch 10/30...\n",
      "Processing batch 11/30...\n",
      "Processing batch 12/30...\n",
      "Processing batch 13/30...\n",
      "Processing batch 14/30...\n",
      "Processing batch 15/30...\n",
      "Processing batch 16/30...\n",
      "Processing batch 17/30...\n",
      "Processing batch 18/30...\n",
      "Processing batch 19/30...\n",
      "Processing batch 20/30...\n",
      "Processing batch 21/30...\n",
      "Processing batch 22/30...\n",
      "Processing batch 23/30...\n",
      "Processing batch 24/30...\n",
      "Processing batch 25/30...\n",
      "Processing batch 26/30...\n",
      "Processing batch 27/30...\n",
      "Processing batch 28/30...\n",
      "Processing batch 29/30...\n",
      "Processing batch 30/30...\n",
      "\n",
      "--- Sentiment Analysis Results ---\n",
      "                                      processed_text sentiment  \\\n",
      "0  aiedgelitertnightly dev litert mobile embedded...   Neutral   \n",
      "1  hcltech q review ai led growth drive record wi...  Positive   \n",
      "2  big tech show use chat gpt total beginner best...  Negative   \n",
      "3  time reconsider cm platform im excited behalf ...  Positive   \n",
      "4  google say invest billion ai data centre capac...  Positive   \n",
      "\n",
      "   sentiment_score  \n",
      "0             0.00  \n",
      "1             0.75  \n",
      "2            -0.50  \n",
      "3             0.60  \n",
      "4             0.55  \n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(CSV_FILE_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file '{CSV_FILE_PATH}' was not found.\")\n",
    "    exit()\n",
    "\n",
    "if 'processed_text' not in df.columns:\n",
    "    print(\"Error: The CSV file must contain a 'processed_text' column.\")\n",
    "    exit()\n",
    "\n",
    "# batch processing to reduce number of api calls\n",
    "all_labels = [] \n",
    "all_scores = []\n",
    "batch_size = 10 \n",
    "headlines_to_process = df['processed_text'].tolist()\n",
    "\n",
    "for i in range(0, len(headlines_to_process), batch_size):\n",
    "    batch = headlines_to_process[i:i+batch_size]\n",
    "    print(f\"Processing batch {i//batch_size + 1}/{(len(headlines_to_process) + batch_size - 1)//batch_size}...\")\n",
    "    \n",
    "    # Get a list of (label, score) tuples for the current batch\n",
    "    results_for_batch = get_sentiment_data_in_batch(batch)\n",
    "    \n",
    "    #  Unpack the tuples into their respective lists for adding into csv\n",
    "    for label, score in results_for_batch:\n",
    "        all_labels.append(label)\n",
    "        all_scores.append(score)\n",
    "    \n",
    "    time.sleep(5) \n",
    "\n",
    "# add generated sentiment columns to the DataFrame\n",
    "df['sentiment_score'] = all_scores\n",
    "df['sentiment'] = all_labels\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- Sentiment Analysis Results ---\")\n",
    "print(df[['processed_text', 'sentiment', 'sentiment_score']].head()) # Show the new columns\n",
    "print(\"------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7af61f2-8d28-4099-9b4b-b8e46a8bcf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>full_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'id': None, 'name': 'Pypi.org'}</td>\n",
       "      <td>ai-edge-litert-nightly 2.0.4.dev20251013</td>\n",
       "      <td>LiteRT is for mobile and embedded devices.</td>\n",
       "      <td>https://pypi.org/project/ai-edge-litert-nightl...</td>\n",
       "      <td>2025-10-14 11:43:13</td>\n",
       "      <td>ai-edge-litert-nightly 2.0.4.dev20251013 LiteR...</td>\n",
       "      <td>aiedgelitertnightly dev litert mobile embedded...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'id': None, 'name': 'Ndtvprofit.com'}</td>\n",
       "      <td>HCLTech Q2 Review: AI Led Growth Drives Record...</td>\n",
       "      <td>HCLTech Ltd. delivered a resilient Q2 FY26 per...</td>\n",
       "      <td>https://www.ndtvprofit.com/research-reports/hc...</td>\n",
       "      <td>2025-10-14 11:43:11</td>\n",
       "      <td>HCLTech Q2 Review: AI Led Growth Drives Record...</td>\n",
       "      <td>hcltech q review ai led growth drive record wi...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'id': None, 'name': 'Independent.ie'}</td>\n",
       "      <td>The Big Tech Show: How to use Chat GPT for tot...</td>\n",
       "      <td>What are the best tips for beginners using AI ...</td>\n",
       "      <td>https://www.independent.ie/podcasts/the-big-te...</td>\n",
       "      <td>2025-10-14 11:43:03</td>\n",
       "      <td>The Big Tech Show: How to use Chat GPT for tot...</td>\n",
       "      <td>big tech show use chat gpt total beginner best...</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'id': None, 'name': 'Realstorygroup.com'}</td>\n",
       "      <td>Time to Reconsider Your CMS Platform?</td>\n",
       "      <td>Iâ€™m very excited on your behalf about the next...</td>\n",
       "      <td>https://www.realstorygroup.com/Blog/time-recon...</td>\n",
       "      <td>2025-10-14 11:41:11</td>\n",
       "      <td>Time to Reconsider Your CMS Platform? Iâ€™m very...</td>\n",
       "      <td>time reconsider cm platform im excited behalf ...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'id': None, 'name': 'Yahoo Entertainment'}</td>\n",
       "      <td>Google says to invest $15 billion in AI data c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://consent.yahoo.com/v2/collectConsent?se...</td>\n",
       "      <td>2025-10-14 11:40:41</td>\n",
       "      <td>Google says to invest $15 billion in AI data c...</td>\n",
       "      <td>google say invest billion ai data centre capac...</td>\n",
       "      <td>0.55</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        source  \\\n",
       "0             {'id': None, 'name': 'Pypi.org'}   \n",
       "1       {'id': None, 'name': 'Ndtvprofit.com'}   \n",
       "2       {'id': None, 'name': 'Independent.ie'}   \n",
       "3   {'id': None, 'name': 'Realstorygroup.com'}   \n",
       "4  {'id': None, 'name': 'Yahoo Entertainment'}   \n",
       "\n",
       "                                               title  \\\n",
       "0           ai-edge-litert-nightly 2.0.4.dev20251013   \n",
       "1  HCLTech Q2 Review: AI Led Growth Drives Record...   \n",
       "2  The Big Tech Show: How to use Chat GPT for tot...   \n",
       "3              Time to Reconsider Your CMS Platform?   \n",
       "4  Google says to invest $15 billion in AI data c...   \n",
       "\n",
       "                                         description  \\\n",
       "0         LiteRT is for mobile and embedded devices.   \n",
       "1  HCLTech Ltd. delivered a resilient Q2 FY26 per...   \n",
       "2  What are the best tips for beginners using AI ...   \n",
       "3  Iâ€™m very excited on your behalf about the next...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                 url          publishedAt  \\\n",
       "0  https://pypi.org/project/ai-edge-litert-nightl...  2025-10-14 11:43:13   \n",
       "1  https://www.ndtvprofit.com/research-reports/hc...  2025-10-14 11:43:11   \n",
       "2  https://www.independent.ie/podcasts/the-big-te...  2025-10-14 11:43:03   \n",
       "3  https://www.realstorygroup.com/Blog/time-recon...  2025-10-14 11:41:11   \n",
       "4  https://consent.yahoo.com/v2/collectConsent?se...  2025-10-14 11:40:41   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  ai-edge-litert-nightly 2.0.4.dev20251013 LiteR...   \n",
       "1  HCLTech Q2 Review: AI Led Growth Drives Record...   \n",
       "2  The Big Tech Show: How to use Chat GPT for tot...   \n",
       "3  Time to Reconsider Your CMS Platform? Iâ€™m very...   \n",
       "4  Google says to invest $15 billion in AI data c...   \n",
       "\n",
       "                                      processed_text  sentiment_score  \\\n",
       "0  aiedgelitertnightly dev litert mobile embedded...             0.00   \n",
       "1  hcltech q review ai led growth drive record wi...             0.75   \n",
       "2  big tech show use chat gpt total beginner best...            -0.50   \n",
       "3  time reconsider cm platform im excited behalf ...             0.60   \n",
       "4  google say invest billion ai data centre capac...             0.55   \n",
       "\n",
       "  sentiment  \n",
       "0   Neutral  \n",
       "1  Positive  \n",
       "2  Negative  \n",
       "3  Positive  \n",
       "4  Positive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b0e2a38-bff2-406e-b9ba-816c6b62103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Successfully saved the results to 'ai_news_with_sentiment_scores.csv'\n"
     ]
    }
   ],
   "source": [
    "#saving\n",
    "output_csv_path = 'ai_news_with_sentiment_scores.csv'\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"\\nâœ… Successfully saved the results to '{output_csv_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924f0a7-39cd-435d-85cc-6ce923194966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
